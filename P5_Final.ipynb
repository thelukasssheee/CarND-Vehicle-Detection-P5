{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Self-Driving Car Engineer, Term 1\n",
    "\n",
    "# Vehicle Detection Project [P5] \n",
    "\n",
    "##### Summary by Michael Berner, Student @ Udacity Self Driving Car NanoDegree 2018, Stuttgart, June 19th 2018\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the testvideo.mp4 and later implement on full projectvideo.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "\n",
    "\n",
    "\n",
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import of libraries DONE!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "% matplotlib inline\n",
    "print('Import of libraries DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SVM, linear scaler and parameters from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading of pickle'd data DONE!\n"
     ]
    }
   ],
   "source": [
    "with open('./svm_scaler_result.pkl', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Read in previously trained Support Vector Machine (SVM)\n",
    "svc = data['svc']\n",
    "\n",
    "# Read in previously fitted scaler\n",
    "X_scaler = data['X_scaler']\n",
    "\n",
    "# Read in parameters which were applied\n",
    "HP = namedtuple('HP', [], verbose=False);\n",
    "HP.colorspace = ['colorspace']\n",
    "HP.HOG_orient = data['orient']\n",
    "HP.pix_per_cell = data['pix_per_cell']\n",
    "HP.cell_per_block = data['cell_per_block']\n",
    "HP.hist_bins = data['hist_bins']\n",
    "HP.spatial_size = data['spatial_size']\n",
    "HP.block_norm = data['block_norm']\n",
    "HP.transform_sqrt = data['transform_sqrt']\n",
    "print(\"Loading of pickle'd data DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minor helper function preparation DONE!\n"
     ]
    }
   ],
   "source": [
    "# Apply threshold to heatmap\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "# Function to draw labeled boxes around detected vehicles\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "\n",
    "# Apply color conversion from RGB to YCrCb\n",
    "def color_conversion(image):\n",
    "    # apply color conversion and return converted image immediately\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "print(\"Minor helper function preparation DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions prepared!\n"
     ]
    }
   ],
   "source": [
    "# Return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True, block_nrm = 'L2-Hys', trans_sqrt = False):\n",
    "    features = hog(img, \n",
    "                   orientations=orient,\n",
    "                   pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                   cells_per_block=(cell_per_block, cell_per_block),\n",
    "                   block_norm= block_nrm,\n",
    "                   transform_sqrt=trans_sqrt,\n",
    "                   visualize=vis,\n",
    "                   feature_vector=feature_vec)\n",
    "    return features\n",
    "    \n",
    "\n",
    "# Return spatial features\n",
    "def get_spatial_features(img, size=(32,32)):\n",
    "    col1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    col2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    col3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((col1,col2,col3))\n",
    "\n",
    "\n",
    "# Return histogram features\n",
    "def get_histogram_features(img, nbins=32):\n",
    "    hist_ch1 = np.histogram(img[:,:,0], bins=nbins)\n",
    "    hist_ch2 = np.histogram(img[:,:,1], bins=nbins)\n",
    "    hist_ch3 = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Create single feature vector by concatenating channels\n",
    "    return np.concatenate((hist_ch1[0], hist_ch2[0], hist_ch3[0]))\n",
    "\n",
    "print(\"Feature extraction functions prepared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual pipeline: \"Car detection\" and \"Image processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline functions prepared!\n"
     ]
    }
   ],
   "source": [
    "def detect_cars(img,HP,svc,X_scaler,scale):\n",
    "    # Initialize variables\n",
    "    count = 0\n",
    "    img_boxes = []\n",
    "    window = 64 # Original window size\n",
    "    \n",
    "    # Prepare heatmap variables\n",
    "    heatmap = np.zeros_like(img[:,:,0])\n",
    "    \n",
    "    # Have it scaled appropriately to have colorspace match the png training data\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    # Reduce search area\n",
    "    img_sub = img[HP.y_lim[0]:HP.y_lim[1],:,:]\n",
    "    \n",
    "    # Apply color conversion from RGB to YCrCb\n",
    "    img_sub = color_conversion(img_sub)\n",
    "    \n",
    "    # Scale image, if necessary\n",
    "    if scale != 1:\n",
    "        imshape = img_sub.shape\n",
    "        img_s_scld = cv2.resize(img_sub, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        #print(\"Scaled sub image from shape\",imshape,\"to\",img_s_scld.shape)\n",
    "    else:\n",
    "        img_s_scld = np.copy(img_sub)\n",
    "    imshape = img_s_scld.shape\n",
    "\n",
    "    # Define blocks and steps\n",
    "    nxblocks = (imshape[1] // HP.pix_per_cell) - 1\n",
    "    nyblocks = (imshape[0] // HP.pix_per_cell) - 1\n",
    "    nfeat_per_block = HP.HOG_orient*HP.cell_per_block**2\n",
    "    \n",
    "    nblocks_per_window = (window // HP.pix_per_cell) - 1\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // HP.cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // HP.cells_per_step\n",
    "    \n",
    "    # Calculate hog channels for the entire scaled sub image\n",
    "    hog1 = get_hog_features(img_s_scld[:,:,0], HP.HOG_orient, HP.pix_per_cell, HP.cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(img_s_scld[:,:,1], HP.HOG_orient, HP.pix_per_cell, HP.cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(img_s_scld[:,:,2], HP.HOG_orient, HP.pix_per_cell, HP.cell_per_block, feature_vec=False)\n",
    "\n",
    "    # Perform sliding window search\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            count += 1\n",
    "            ypos = yb*HP.cells_per_step\n",
    "            xpos = xb*HP.cells_per_step\n",
    "            hogfeat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "            hogfeat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "            hogfeat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "            hog_features = np.hstack((hogfeat1,hogfeat2,hogfeat3))\n",
    "    \n",
    "            xleft = xpos*HP.pix_per_cell\n",
    "            ytop = ypos*HP.pix_per_cell\n",
    "            \n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(img_s_scld[ytop:ytop+window, xleft:xleft+window],(64,64))\n",
    "            \n",
    "            # Get color features\n",
    "            spatial_features = get_spatial_features(subimg, size=HP.spatial_size)\n",
    "            hist_features = get_histogram_features(subimg, nbins=HP.hist_bins)\n",
    "            \n",
    "            # Stack features, apply scaler and make a prediction\n",
    "            all_features = np.hstack((hog_features,spatial_features, hist_features))\n",
    "            test_features = X_scaler.transform(all_features.reshape(1,-1))\n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            # If a positive match was found, add value to heatmap\n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                heatmap[ytop_draw+HP.y_lim[0]:ytop_draw+win_draw+HP.y_lim[0], xbox_left:xbox_left+win_draw] += 1\n",
    "    # Return heatmap as function output\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    global buffer\n",
    "    # Walk through \n",
    "    heatmap1 = detect_cars(image.astype(np.float32)/255,HP,svc,X_scaler,scale[0])\n",
    "    heatmap2 = detect_cars(image.astype(np.float32)/255,HP,svc,X_scaler,scale[1])\n",
    "    heatmap3 = detect_cars(image.astype(np.float32)/255,HP,svc,X_scaler,scale[2])\n",
    "    heatmap4 = detect_cars(image.astype(np.float32)/255,HP,svc,X_scaler,scale[3])\n",
    "    heatmap5 = detect_cars(image.astype(np.float32)/255,HP,svc,X_scaler,scale[4])\n",
    "    heatmap = heatmap1+heatmap2+heatmap3+heatmap4+heatmap5\n",
    "\n",
    "    # Store heatmap in double ended queue buffer, calculate averaged heatmap over 10 frames (i.e. buffer size)\n",
    "    buffer.append(heatmap)\n",
    "    heatmap_avg = np.average(buffer,0)\n",
    "    heatmap_avg = apply_threshold(heatmap_avg, np.max(heatmap_avg)*0.2)\n",
    "    heatmap_avg = apply_threshold(heatmap_avg, 3)\n",
    "\n",
    "    # Detect labels for individual vehicles\n",
    "    labels = label(heatmap_avg)\n",
    "    \n",
    "    return draw_labeled_bboxes(np.copy(image),labels)\n",
    "\n",
    "print(\"Pipeline functions prepared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process video file and show it in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video out_final.mp4\n",
      "[MoviePy] Writing video out_final.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [1:34:13<00:04,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: out_final.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from collections import deque\n",
    "\n",
    "# Initialize buffer for heatmap, define it as global variable\n",
    "buffer = deque(maxlen=10)\n",
    "scale = [1, 1.2500, 1.500, 1.8125, 2.2188]\n",
    "HP.y_lim = [400,656]\n",
    "HP.cells_per_step = 2\n",
    "global buffer,HP,svc,X_scaler,scale\n",
    "\n",
    "# Process video file\n",
    "test_output = 'out_final.mp4'\n",
    "# clip = VideoFileClip('test_video.mp4')\n",
    "clip = VideoFileClip('project_video.mp4')\n",
    "test_clip = clip.fl_image(process_image)\n",
    "test_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"out_final.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
